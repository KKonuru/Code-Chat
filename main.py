from ollama import chat, ChatResponse,embeddings
from ollama import ChatResponse
from langchain_ollama import ChatOllama
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import Language,RecursiveCharacterTextSplitter
from transformers import RobertaTokenizer, RobertaModel
import torch
import os
import faiss
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_core.documents import Document
import numpy as np
from Embedding import CodeEmbeddingFunction
from uuid import uuid4
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

#A chatbot that is instatiated for a specific code repository
class codeChat():
    def __init__(self,path:str,temperature:float):

        #CodeBert is used. This ensures the gpu is used to speed up embedding
        if torch.cuda.is_available():
            torch.set_default_device("cuda")
        elif torch.backends.mps.is_available():
            torch.set_default_device("mps")
        
        self._llm = ChatOllama(
            model = "codellama:13b",
            temperature = temperature,
            # other params ...
        )
        self._embedding= CodeEmbeddingFunction()

        self._path = path
        self._vectorstore = self.createVectorStores()

    def summarizeCode(self,code:str)->str:
        template = """
            Your job is to summarize the code snippet into human language. You are going to be given React code that is either javascript,typescript, or html.
            Describe what is in the code and some relationships it may have to help vector search the code snippet.

            Code: {code}

            Answer: """
        prompt_template = PromptTemplate(
            input_variables = ["code"],
            template = template
        )
        response = self._llm.invoke(prompt_template.format(code=code))
        #Return the string of the response
        return response.content

    def queryTranslation(self,query:str)->str:
        template = """
            Your job is to translate the query into text that will index the vector database. The vector database contains vectors of summaries
            generated by a llm on chunks of code. I want you to best describe the code to look for in a way that will help me find the most relevant code snippets.

            Query: {query}

            Answer: """
        prompt_template = PromptTemplate(
            input_variables = ["query"],
            template = template
        )
        response = self._llm.invoke(prompt_template.format(query=query))
        return response.content

    def getDocuments(self,files:list[str]) -> list[Document]:
        docs = []
        for file in files:
            lang = file.split(".")[-1]
            with open(os.path.join(self._path,file),"r") as f:
                code = f.read()
            parent_dir = self._path.split("/")[-1]
            if file.index("/")!=-1:
                parent_dir = file.split("/")[0]
            document = Document(
                page_content = code,
                metadata = {"lang":Language(lang),"file":file,"parent_dir":parent_dir}
            )
            docs.append(document)
        return docs

    def splitDocs(self,docs:list[Document]) -> list[Document]:
        splitter_dict = {}
        split_docs = []
        for doc in docs:
            lang = doc.metadata["lang"]
            if lang not in splitter_dict:
                splitter_dict[lang] = RecursiveCharacterTextSplitter.from_language(language=lang,chunk_size=500,chunk_overlap=25)
            split_doc = splitter_dict[lang].create_documents([doc.page_content]) #Split_doc is a type list of documents
            for s in split_doc:
                s.metadata = doc.metadata
            split_docs.extend(split_doc)
        return split_docs
    
    def humanSumarizedDocs(self,docs:list[Document])->list[Document]:
        human_docs = []
        for doc in docs:
            new_dict = doc.metadata
            new_dict["code"] = doc.page_content
            human_docs.append(
                Document(
                    page_content = self.summarizeCode(doc.page_content),
                    metadata = new_dict
                )
            )
        return human_docs
    
    def createVectorStores(self)->FAISS:
        files = self.getFileNames()
        #To use the splitter, we need to create Documents for the files
        chunked_docs = self.splitDocs(self.getDocuments(files))
        
        #Create human summaries for the code snippets
        chunked_docs = self.humanSumarizedDocs(chunked_docs)
        #Create a vector store
        vector_store = FAISS(
            index = faiss.IndexFlatIP(768),
            embedding_function=self._embedding,
            docstore=InMemoryDocstore(),
            index_to_docstore_id={}
        )
        uuids = [str(uuid4()) for _ in range(len(chunked_docs))]
        vector_store.add_documents(chunked_docs)

        return vector_store

    def getFileNames(self):
        files = []
        dir = self._path
        allowed_file_exts= [e.value for e in Language]
        # Loop through the files in the main directory
        for file in os.listdir(dir):
            if not file.endswith(tuple(allowed_file_exts)):
                continue
            file_path = os.path.join(dir, file)
            if os.path.isfile(file_path):
                files.append(file)
        
        # For any subdirectories, loop through them and add the file name with the path starting at dir
        for subdir, dirs, filenames in os.walk(dir):
            for file in filenames:
                if not file.endswith(tuple(allowed_file_exts)):
                    continue
                # Construct the relative path
                relative_path = os.path.relpath(os.path.join(subdir, file), dir)
                files.append(relative_path)
        
        return list(set(files))
    
    def getDocs(self,query:str)->str:
        docs = self._vectorstore.similarity_search(
            self.queryTranslation(query),
            k=5
        )
        return "\n\n".join(doc.page_content for doc in docs)
    
    def llmResponse(self,query:str)->str:
        template = """

            Your job is to generate a response to the query. The query is a question about code that you need to answer. You can use the code snippets that are provided to you to help you answer the question.
            Write out the entire code snippet that was helpful for the question.
            If you are not given any relevant code snippets you will respond with \"I do not have the necessary information to answer your question\"
            
            Query: {query}

            Context: {context}
            
            Answer:"""
        
        prompt = ChatPromptTemplate.from_template(template)
        chain = prompt | self._llm | StrOutputParser()
        return chain.stream({
            "query":query,
            "context":self.getDocs(query)
        })

    def adjustTemperature(self,temperature:float):
        self._llm.temperature = temperature
        
    
def main():
    proj_dir ="/Users/kausthubhkonuru/Personal Projects/counter-assignment" #input("Enter the path to the project directory: ")
    chatbot = codeChat(proj_dir)
    while True:
        query = input("Enter your query: ")
        stream_obj = chatbot.llmResponse(query)
        
        # Print items one by one
        result = "".join(stream_obj)
        print(result) 

    
if __name__== "__main__":
    main()